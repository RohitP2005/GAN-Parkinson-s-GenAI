{"cells":[{"cell_type":"markdown","metadata":{},"source":["# GANN Synthetic MRI generator"]},{"cell_type":"markdown","metadata":{},"source":["### Loading Preprocessed data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1727810359038,"user":{"displayName":"Rohit P","userId":"18209259416739582638"},"user_tz":-330},"id":"leN_R_mgMrF9","outputId":"51ea2b97-d9cc-4670-c269-74e821427338"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset: X, Shape: (54, 176, 240, 205), Data type: float64\n","Dataset: Y, Shape: (54,), Data type: |S10\n"]}],"source":["import h5py\n","\n","# Load the h5py file\n","file_path = './mri_data_balanced.h5'\n","with h5py.File(file_path, 'r') as f:\n","    # Function to recursively print the structure of the file\n","    def print_structure(name, obj):\n","        if isinstance(obj, h5py.Group):\n","            print(f\"Group: {name}\")\n","        elif isinstance(obj, h5py.Dataset):\n","            print(f\"Dataset: {name}, Shape: {obj.shape}, Data type: {obj.dtype}\")\n","\n","    # Visit all groups and datasets in the file\n","    f.visititems(print_structure)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30840,"status":"ok","timestamp":1727808090017,"user":{"displayName":"Rohit P","userId":"18209259416739582638"},"user_tz":-330},"id":"_JAZz5ZMM8Sl","outputId":"995ecd7e-c3f5-4c04-f281-38012f9fa9b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["MRI Data Shape: (54, 176, 240, 205)\n","Labels: ['PD', 'NORMAL', 'NORMAL', 'NORMAL', 'PD', 'PD', 'NORMAL', 'PD', 'PD', 'PD', 'PD', 'NORMAL', 'PD', 'NORMAL', 'NORMAL', 'NORMAL', 'PD', 'PD', 'NORMAL', 'PD', 'PD', 'NORMAL', 'PD', 'PD', 'NORMAL', 'NORMAL', 'PD', 'NORMAL', 'PD', 'PD', 'PD', 'PD', 'PD', 'PD', 'NORMAL', 'PD', 'NORMAL', 'NORMAL', 'PD', 'PD', 'PD', 'PD', 'PD', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL', 'NORMAL']\n"]}],"source":["import numpy as np\n","\n","with h5py.File(file_path, 'r') as f:\n","    # Load MRI data\n","    X = np.array(f['X'])  # Shape: (54, 176, 240, 205)\n","\n","    # Load labels\n","    Y = np.array(f['Y'])  # Shape: (54,)\n","    Y = [y.decode('utf-8') for y in Y]  # Decode the byte strings to regular strings\n","\n","# Check the shapes and labels\n","print(f\"MRI Data Shape: {X.shape}\")\n","print(f\"Labels: {Y}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Augmenting Data "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27809,"status":"ok","timestamp":1727808122637,"user":{"displayName":"Rohit P","userId":"18209259416739582638"},"user_tz":-330},"id":"qWK-UQpUNZSs","outputId":"127d742c-5267-4157-e94c-32be6cc93115"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torchio\n","  Downloading torchio-0.20.0-py2.py3-none-any.whl.metadata (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting Deprecated (from torchio)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n","Collecting SimpleITK!=2.0.*,!=2.1.1.1 (from torchio)\n","  Downloading SimpleITK-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n","Collecting humanize (from torchio)\n","  Downloading humanize-4.10.0-py3-none-any.whl.metadata (7.9 kB)\n","Collecting nibabel (from torchio)\n","  Downloading nibabel-5.2.1-py3-none-any.whl.metadata (8.8 kB)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from torchio) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torchio) (1.13.1)\n","Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.10/dist-packages (from torchio) (2.4.0+cpu)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchio) (4.66.5)\n","Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from torchio) (0.12.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1->torchio) (2024.9.0)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->torchio) (1.14.1)\n","Requirement already satisfied: packaging>=17 in /usr/local/lib/python3.10/dist-packages (from nibabel->torchio) (24.1)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer->torchio) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer->torchio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer->torchio) (13.8.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer->torchio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer->torchio) (2.18.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1->torchio) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1->torchio) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->torchio) (0.1.2)\n","Downloading torchio-0.20.0-py2.py3-none-any.whl (175 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading SimpleITK-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Downloading humanize-4.10.0-py3-none-any.whl (126 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.0/127.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nibabel-5.2.1-py3-none-any.whl (3.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: SimpleITK, nibabel, humanize, Deprecated, torchio\n","Successfully installed Deprecated-1.2.14 SimpleITK-2.4.0 humanize-4.10.0 nibabel-5.2.1 torchio-0.20.0\n"]}],"source":["!pip install torchio"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62754,"status":"ok","timestamp":1727808205147,"user":{"displayName":"Rohit P","userId":"18209259416739582638"},"user_tz":-330},"id":"xLZSvGs5NWNK","outputId":"458cc3e6-4775-4072-fcfa-b1cf5db499c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Augmented MRI Data Shape: (54, 1, 176, 240, 205)\n","Augmented Labels: ['PD' 'NORMAL' 'NORMAL' 'NORMAL' 'PD' 'PD' 'NORMAL' 'PD' 'PD' 'PD' 'PD'\n"," 'NORMAL' 'PD' 'NORMAL' 'NORMAL' 'NORMAL' 'PD' 'PD' 'NORMAL' 'PD' 'PD'\n"," 'NORMAL' 'PD' 'PD' 'NORMAL' 'NORMAL' 'PD' 'NORMAL' 'PD' 'PD' 'PD' 'PD'\n"," 'PD' 'PD' 'NORMAL' 'PD' 'NORMAL' 'NORMAL' 'PD' 'PD' 'PD' 'PD' 'PD'\n"," 'NORMAL' 'NORMAL' 'NORMAL' 'NORMAL' 'NORMAL' 'NORMAL' 'NORMAL' 'NORMAL'\n"," 'NORMAL' 'NORMAL' 'NORMAL']\n"]}],"source":["import torchio as tio\n","\n","\n","# Define the augmentation transforms\n","transforms = tio.Compose([\n","    tio.RandomFlip(axes=(0, 1, 2)),  # Flip along different axes\n","    tio.RandomAffine(scales=(0.9, 1.1), degrees=10),  # Random scaling and rotation\n","    tio.RandomNoise(mean=0, std=0.1),  # Adding Gaussian noise\n","    tio.RandomElasticDeformation()  # Elastic deformation\n","])\n","\n","# Create lists to hold the augmented data and labels\n","augmented_data = []\n","augmented_labels = []\n","\n","# Augment both PD and NORMAL labeled MRIs\n","for i in range(len(X)):\n","    # Add channel dimension to make the data 4D: (1, H, W, D)\n","    mri_sample = X[i][np.newaxis, ...]\n","\n","    # Convert the MRI data to a format for TorchIO\n","    subject = tio.Subject(mri=tio.ScalarImage(tensor=mri_sample.astype(np.float32)))\n","\n","    # Apply the augmentation\n","    augmented_subject = transforms(subject)\n","\n","    # Get augmented MRI and add to the augmented data list\n","    augmented_mri = augmented_subject['mri'].data.numpy()\n","    augmented_data.append(augmented_mri)\n","\n","    # Append the corresponding label for the augmented data\n","    augmented_labels.append(Y[i])\n","\n","# Convert the augmented data and labels to NumPy arrays\n","augmented_data = np.array(augmented_data)\n","augmented_labels = np.array(augmented_labels)\n","\n","# Print the new augmented data shape\n","print(f\"Augmented MRI Data Shape: {augmented_data.shape}\")\n","print(f\"Augmented Labels: {augmented_labels}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Encoding Y labels and saving the data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":94297,"status":"ok","timestamp":1727808523084,"user":{"displayName":"Rohit P","userId":"18209259416739582638"},"user_tz":-330},"id":"J3hW4TyRZYqj","outputId":"25c0f594-08c6-4436-ec9e-b5fd2c8be8ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Augmented data saved to /content/drive/MyDrive/mri_data_augmented.h5\n"]}],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","label_encoder = LabelEncoder()\n","encoded_labels = label_encoder.fit_transform(augmented_labels)\n","\n","output_file_path = './mri_data_augmented.h5'\n","\n","# Open a new h5py file to write the augmented data\n","with h5py.File(output_file_path, 'w') as f:\n","    # Save the augmented MRI data\n","    f.create_dataset('X_augmented', data=augmented_data, compression=\"gzip\")\n","\n","    # Save the encoded labels\n","    f.create_dataset('Y_augmented', data=encoded_labels, compression=\"gzip\")\n","\n","print(f\"Augmented data saved to {output_file_path}\")\n"]},{"cell_type":"markdown","metadata":{"id":"RoL2WfREa1HC"},"source":["### load augmented data"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":620,"status":"ok","timestamp":1727819937849,"user":{"displayName":"Rohit P","userId":"18209259416739582638"},"user_tz":-330},"id":"-U4jiANqd5vx"},"outputs":[],"source":["import h5py\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import numpy as np\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o4ClN2gpd4we"},"outputs":[],"source":["# Custom Dataset for loading MRI data\n","class MRIDataset(Dataset):\n","    def __init__(self, h5_file):\n","        with h5py.File(h5_file, 'r') as f:\n","            self.X = f['X_augmented'][:]  # Assuming your augmented MRI images are stored in 'X'\n","            self.Y = f['Y_augmented'][:]  # Assuming labels are stored in 'Y_augmented', not 'X_augmented'\n","        self.Y = self.Y.astype(np.float32) #  Casting to float32 for compatibility with PyTorch\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        image = self.X[idx]\n","        label = self.Y[idx]\n","        # Removing the extra dimension addition, allowing the Dataloader to handle batching\n","        # image = np.expand_dims(image, axis=0)\n","        return torch.tensor(image, dtype=torch.float32), torch.tensor(label)\n","\n","# Initialize dataset and dataloader\n","h5_file = './mri_data_augmented.h5'  # Replace with your augmented h5 file path\n","dataset = MRIDataset(h5_file)\n","dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Define GAN architecture "]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":516,"status":"ok","timestamp":1727819943012,"user":{"displayName":"Rohit P","userId":"18209259416739582638"},"user_tz":-330},"id":"wUwOCKWKeNQW"},"outputs":[],"source":["# Define the GAN architecture\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.ConvTranspose3d(100, 256, kernel_size=4, stride=1, padding=0),\n","            nn.ReLU(),\n","            nn.ConvTranspose3d(256, 128, kernel_size=4, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.ConvTranspose3d(128, 1, kernel_size=4, stride=2, padding=1),\n","            nn.Tanh(),  # Assuming input images are normalized between -1 and 1\n","        )\n","\n","    def forward(self, z):\n","        return self.model(z)\n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv3d(1, 128, kernel_size=4, stride=2, padding=1),\n","            nn.LeakyReLU(0.2),\n","            nn.Conv3d(128, 256, kernel_size=4, stride=2, padding=1),\n","            nn.LeakyReLU(0.2),\n","            nn.Conv3d(256, 1, kernel_size=4, stride=1, padding=0),\n","            nn.Sigmoid(),  # Output probability for real or fake\n","        )\n","\n","    def forward(self, x):\n","        return self.model(x)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2503,"status":"ok","timestamp":1727819951407,"user":{"displayName":"Rohit P","userId":"18209259416739582638"},"user_tz":-330},"id":"ttBxaI8WeQlD"},"outputs":[],"source":["# Instantiate models, loss function, and optimizers\n","generator = Generator()\n","discriminator = Discriminator()\n","criterion = nn.BCELoss()  # Binary Cross Entropy loss\n","optimizer_g = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))"]},{"cell_type":"markdown","metadata":{},"source":["### Run Training"]},{"cell_type":"markdown","metadata":{},"source":["#### code to load checkpoint model\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load the saved checkpoint\n","checkpoint = torch.load('checkpoint_path_of_GANN_model')\n","\n","# Load the models\n","generator.load_state_dict(checkpoint['generator_state_dict'])\n","discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n","\n","# Load the optimizers\n","optimizer_g.load_state_dict(checkpoint['optimizer_g_state_dict'])\n","optimizer_d.load_state_dict(checkpoint['optimizer_d_state_dict'])\n","\n","# Load the epoch to resume training from\n","start_epoch = checkpoint['epoch']\n","\n","print(f\"Resuming training from epoch {start_epoch + 1}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8862258,"status":"ok","timestamp":1727819249007,"user":{"displayName":"Rohit P","userId":"18209259416739582638"},"user_tz":-330},"id":"9al2hkJsef26","outputId":"18ac30c2-d71a-407f-b57a-37e147c31005"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/100], D Loss: 1.0258734226226807, G Loss: 0.6862360835075378\n","Epoch [2/100], D Loss: 1.0170859098434448, G Loss: 0.6889603137969971\n","Epoch [3/100], D Loss: 1.0130282640457153, G Loss: 0.6904316544532776\n","Epoch [4/100], D Loss: 1.0113495588302612, G Loss: 0.6908804774284363\n","Epoch [5/100], D Loss: 1.009940505027771, G Loss: 0.6916881203651428\n","Epoch [6/100], D Loss: 1.009946584701538, G Loss: 0.6916550993919373\n","Epoch [7/100], D Loss: 1.0090763568878174, G Loss: 0.692183792591095\n","Epoch [8/100], D Loss: 1.009307622909546, G Loss: 0.6920391917228699\n","Epoch [9/100], D Loss: 1.0090856552124023, G Loss: 0.692150890827179\n","Epoch [10/100], D Loss: 1.0078866481781006, G Loss: 0.6925312876701355\n","Epoch [11/100], D Loss: 1.0077693462371826, G Loss: 0.6925809383392334\n","Epoch [12/100], D Loss: 1.007596731185913, G Loss: 0.6926838755607605\n","Epoch [13/100], D Loss: 1.0073738098144531, G Loss: 0.6927151083946228\n","Epoch [14/100], D Loss: 1.0073097944259644, G Loss: 0.6927604675292969\n","Epoch [15/100], D Loss: 1.007185935974121, G Loss: 0.6927766799926758\n","Epoch [16/100], D Loss: 1.007187008857727, G Loss: 0.6927550435066223\n","Epoch [17/100], D Loss: 1.0073139667510986, G Loss: 0.6927215456962585\n","Epoch [18/100], D Loss: 1.0074677467346191, G Loss: 0.6926437020301819\n","Epoch [19/100], D Loss: 1.0078072547912598, G Loss: 0.6925437450408936\n","Epoch [20/100], D Loss: 1.008007287979126, G Loss: 0.6924459934234619\n","Epoch [21/100], D Loss: 1.0079519748687744, G Loss: 0.6925291419029236\n","Epoch [22/100], D Loss: 1.00762939453125, G Loss: 0.6926053166389465\n","Epoch [23/100], D Loss: 1.0075777769088745, G Loss: 0.692620575428009\n","Epoch [24/100], D Loss: 1.007404088973999, G Loss: 0.6927195191383362\n","Epoch [25/100], D Loss: 1.007285237312317, G Loss: 0.6927428841590881\n","Epoch [26/100], D Loss: 1.0071518421173096, G Loss: 0.6928195953369141\n","Epoch [27/100], D Loss: 1.007025957107544, G Loss: 0.6928680539131165\n","Epoch [28/100], D Loss: 1.0069248676300049, G Loss: 0.6929111480712891\n","Epoch [29/100], D Loss: 1.0068141222000122, G Loss: 0.6929636001586914\n","Epoch [30/100], D Loss: 1.006758689880371, G Loss: 0.692983090877533\n","Epoch [31/100], D Loss: 1.0067168474197388, G Loss: 0.6930049061775208\n","Epoch [32/100], D Loss: 1.006653070449829, G Loss: 0.6930213570594788\n","Epoch [33/100], D Loss: 1.0066410303115845, G Loss: 0.6930370330810547\n","Epoch [34/100], D Loss: 1.0066249370574951, G Loss: 0.6930460333824158\n","Epoch [35/100], D Loss: 1.0066001415252686, G Loss: 0.6930596232414246\n","Epoch [36/100], D Loss: 1.0065927505493164, G Loss: 0.6930615901947021\n","Epoch [37/100], D Loss: 1.0065770149230957, G Loss: 0.6930713057518005\n","Epoch [38/100], D Loss: 1.006544828414917, G Loss: 0.6930789947509766\n","Epoch [39/100], D Loss: 1.006553053855896, G Loss: 0.693077564239502\n","Epoch [40/100], D Loss: 1.0065381526947021, G Loss: 0.69309002161026\n","Epoch [41/100], D Loss: 1.0065374374389648, G Loss: 0.6930842399597168\n","Epoch [42/100], D Loss: 1.0065292119979858, G Loss: 0.6930883526802063\n","Epoch [43/100], D Loss: 1.0065242052078247, G Loss: 0.6930928826332092\n","Epoch [44/100], D Loss: 1.006516933441162, G Loss: 0.6930968165397644\n","Epoch [45/100], D Loss: 1.006516456604004, G Loss: 0.693095862865448\n","Epoch [46/100], D Loss: 1.0065091848373413, G Loss: 0.6930949687957764\n","Epoch [47/100], D Loss: 1.0065069198608398, G Loss: 0.6931002140045166\n","Epoch [48/100], D Loss: 1.0065021514892578, G Loss: 0.6931032538414001\n","Epoch [49/100], D Loss: 1.0064963102340698, G Loss: 0.6931065917015076\n","Epoch [50/100], D Loss: 1.0064929723739624, G Loss: 0.6931062340736389\n","Epoch [51/100], D Loss: 1.0064963102340698, G Loss: 0.6931009292602539\n","Epoch [52/100], D Loss: 1.0064934492111206, G Loss: 0.6931049227714539\n","Epoch [53/100], D Loss: 1.0064880847930908, G Loss: 0.6931095719337463\n","Epoch [54/100], D Loss: 1.0064910650253296, G Loss: 0.6931042671203613\n","Epoch [55/100], D Loss: 1.0064716339111328, G Loss: 0.6931080222129822\n","Epoch [56/100], D Loss: 1.006478190422058, G Loss: 0.6931158900260925\n","Epoch [57/100], D Loss: 1.0064741373062134, G Loss: 0.6931188702583313\n","Epoch [58/100], D Loss: 1.006466269493103, G Loss: 0.6931187510490417\n","Epoch [59/100], D Loss: 1.0064717531204224, G Loss: 0.6931121945381165\n","Epoch [60/100], D Loss: 1.0064774751663208, G Loss: 0.6931123733520508\n","Epoch [61/100], D Loss: 1.006478190422058, G Loss: 0.6931099891662598\n","Epoch [62/100], D Loss: 1.0064655542373657, G Loss: 0.6931217312812805\n","Epoch [63/100], D Loss: 1.0064647197723389, G Loss: 0.6931175589561462\n","Epoch [64/100], D Loss: 1.0064685344696045, G Loss: 0.6931178569793701\n","Epoch [65/100], D Loss: 1.0064624547958374, G Loss: 0.6931233406066895\n","Epoch [66/100], D Loss: 1.0064666271209717, G Loss: 0.6931187510490417\n","Epoch [67/100], D Loss: 1.0064544677734375, G Loss: 0.6931200623512268\n","Epoch [68/100], D Loss: 1.0064622163772583, G Loss: 0.6931214332580566\n","Epoch [69/100], D Loss: 1.0064603090286255, G Loss: 0.6931179165840149\n","Epoch [70/100], D Loss: 1.0064635276794434, G Loss: 0.6931142807006836\n","Epoch [71/100], D Loss: 1.0064579248428345, G Loss: 0.6931231617927551\n","Epoch [72/100], D Loss: 1.006458044052124, G Loss: 0.6931220889091492\n","Epoch [73/100], D Loss: 1.0064616203308105, G Loss: 0.6931203007698059\n","Epoch [74/100], D Loss: 1.0064563751220703, G Loss: 0.6931244730949402\n","Epoch [75/100], D Loss: 1.0064555406570435, G Loss: 0.693122148513794\n","Epoch [76/100], D Loss: 1.0064585208892822, G Loss: 0.6931211352348328\n","Epoch [77/100], D Loss: 1.0064536333084106, G Loss: 0.693124532699585\n","Epoch [78/100], D Loss: 1.0064483880996704, G Loss: 0.6931307911872864\n","Epoch [79/100], D Loss: 1.0064568519592285, G Loss: 0.6931216716766357\n","Epoch [80/100], D Loss: 1.0064524412155151, G Loss: 0.6931247711181641\n","Epoch [81/100], D Loss: 1.0064486265182495, G Loss: 0.693128764629364\n","Epoch [82/100], D Loss: 1.0064505338668823, G Loss: 0.6931242942810059\n","Epoch [83/100], D Loss: 1.0064516067504883, G Loss: 0.6931255459785461\n","Epoch [84/100], D Loss: 1.0064527988433838, G Loss: 0.6931224465370178\n","Epoch [85/100], D Loss: 1.0064464807510376, G Loss: 0.693126916885376\n","Epoch [86/100], D Loss: 1.0064527988433838, G Loss: 0.6931234002113342\n","Epoch [87/100], D Loss: 1.0064443349838257, G Loss: 0.6931275725364685\n","Epoch [88/100], D Loss: 1.006450891494751, G Loss: 0.6931245923042297\n","Epoch [89/100], D Loss: 1.0064482688903809, G Loss: 0.6931273341178894\n","Epoch [90/100], D Loss: 1.006449580192566, G Loss: 0.6931247711181641\n","Epoch [91/100], D Loss: 1.0064468383789062, G Loss: 0.6931254267692566\n","Epoch [92/100], D Loss: 1.006448745727539, G Loss: 0.6931262016296387\n","Epoch [93/100], D Loss: 1.0064446926116943, G Loss: 0.6931264996528625\n","Epoch [94/100], D Loss: 1.006446123123169, G Loss: 0.6931271553039551\n","Epoch [95/100], D Loss: 1.0064468383789062, G Loss: 0.6931257843971252\n","Epoch [96/100], D Loss: 1.0064469575881958, G Loss: 0.6931269764900208\n","Epoch [97/100], D Loss: 1.0064458847045898, G Loss: 0.6931288838386536\n","Epoch [98/100], D Loss: 1.00644850730896, G Loss: 0.6931248307228088\n","Epoch [99/100], D Loss: 1.0064475536346436, G Loss: 0.6931269764900208\n","Epoch [100/100], D Loss: 1.0064455270767212, G Loss: 0.6931278109550476\n"]}],"source":["# Training loop\n","num_epochs = 100  # Set the number of epochs\n","for epoch in range(num_epochs):\n","    for real_images, _ in dataloader:\n","        batch_size = real_images.size(0)\n","\n","        # Create labels for real and fake images\n","        real_labels = torch.ones(batch_size, 1)\n","        fake_labels = torch.zeros(batch_size, 1)\n","\n","        # Train the Discriminator\n","        optimizer_d.zero_grad()\n","        outputs = discriminator(real_images)  # Use real images\n","        # Reshape the discriminator output to match the label shape\n","        outputs = outputs.view(batch_size, -1)  # Flatten the output\n","        #before applying sigmoid function.\n","        outputs = torch.sigmoid(outputs)\n","        # Calculate loss after reshaping\n","        d_loss_real = criterion(outputs[:,0], real_labels.view(-1))  # Calculate loss\n","                                                           #after flattening outputs.\n","\n","\n","        noise = torch.randn(batch_size, 100, 1, 1, 1)  # Random noise for the generator\n","        fake_images = generator(noise)\n","        outputs = discriminator(fake_images.detach())\n","        # Reshape the discriminator output to match the label shape\n","        outputs = outputs.view(batch_size, -1) # Flatten the output\n","                                              # before applying sigmoid\n","                                              #function.\n","        outputs = torch.sigmoid(outputs)\n","        # Calculate loss after reshaping\n","        d_loss_fake = criterion(outputs[:,0], fake_labels.view(-1))   #Calculate loss\n","                                                            #after flattening outputs.\n","\n","        d_loss = d_loss_real + d_loss_fake\n","        d_loss.backward()\n","        optimizer_d.step()\n","\n","        # Train the Generator\n","        optimizer_g.zero_grad()\n","        outputs = discriminator(fake_images)\n","        # Reshape the discriminator output to match the label shape\n","        outputs = outputs.view(batch_size, -1) # Flatten the output before\n","                                              #applying sigmoid function.\n","        outputs = torch.sigmoid(outputs)\n","        # Calculate loss after reshaping\n","        g_loss = criterion(outputs[:,0], real_labels.view(-1)) #Calculate loss\n","                                                             #after flattening outputs.\n","        g_loss.backward()\n","        optimizer_g.step()\n","\n","    print(f\"Epoch [{epoch + 1}/{num_epochs}], D Loss: {d_loss.item()}, G Loss: {g_loss.item()}\")\n","\n","# Save the models if needed\n","# torch.save(generator.state_dict(), 'generator.pth')\n","# torch.save(discriminator.state_dict(), 'discriminator.pth')"]},{"cell_type":"markdown","metadata":{},"source":["### Use if u want to train model later using checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define a path to save the model checkpoints\n","checkpoint_path = \"./gan_checkpoint.pth\"\n","\n","# Save the generator, discriminator, and optimizer states\n","torch.save({\n","    'epoch': epoch,\n","    'generator_state_dict': generator.state_dict(),\n","    'discriminator_state_dict': discriminator.state_dict(),\n","    'optimizer_g_state_dict': optimizer_g.state_dict(),\n","    'optimizer_d_state_dict': optimizer_d.state_dict(),\n","    'd_loss': d_loss.item(),\n","    'g_loss': g_loss.item(),\n","}, checkpoint_path)\n","\n","print(f\"Model saved after {epoch + 1} epochs.\")"]},{"cell_type":"markdown","metadata":{},"source":["### Saving the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dUNOTe_p4j6T"},"outputs":[],"source":["# Save the models if needed\n","torch.save(generator.state_dict(), '/content/drive/MyDrive/generator.pth')\n","torch.save(discriminator.state_dict(), '/content/drive/MyDrive/discriminator.pth')"]},{"cell_type":"markdown","metadata":{},"source":["### Loading the model"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5807,"status":"ok","timestamp":1727820027646,"user":{"displayName":"Rohit P","userId":"18209259416739582638"},"user_tz":-330},"id":"WFBantFfFHut","outputId":"6220175a-8fd2-4cdf-a36f-d6bdbbcabd64"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-8-8e45f002fdd7>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  generator.load_state_dict(torch.load('/content/drive/MyDrive/generator.pth'))\n","<ipython-input-8-8e45f002fdd7>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  discriminator.load_state_dict(torch.load('/content/drive/MyDrive/discriminator.pth'))\n"]},{"name":"stdout","output_type":"stream","text":["Generator and Discriminator loaded successfully.\n"]}],"source":["import torch\n","import nibabel as nib\n","\n","\n","# Load the state dicts from the saved .pth files\n","generator.load_state_dict(torch.load('/content/drive/MyDrive/generator.pth'))\n","discriminator.load_state_dict(torch.load('/content/drive/MyDrive/discriminator.pth'))\n","\n","# Set the models to evaluation mode\n","generator.eval()\n","discriminator.eval()\n","\n","print(\"Generator and Discriminator loaded successfully.\")\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":554,"status":"ok","timestamp":1727820045941,"user":{"displayName":"Rohit P","userId":"18209259416739582638"},"user_tz":-330},"id":"nm0_NZ8sGYww","outputId":"05971d40-fac3-467a-ea5f-9f7ab1365737"},"outputs":[{"name":"stdout","output_type":"stream","text":["Generated and saved: generated_image_1.nii\n","Generated and saved: generated_image_2.nii\n","Generated and saved: generated_image_3.nii\n"]}],"source":["import os\n","import torch\n","import nibabel as nib\n","import numpy as np\n","from datetime import datetime\n","\n","# Generate synthetic MRI images using the loaded generator\n","def generate_synthetic_images(generator, num_images=1, save_as_nii=True):\n","    generator.eval()  # Set generator to evaluation mode\n","\n","    # Generate random noise for input to the generator\n","    noise = torch.randn(num_images, 100, 1, 1, 1)  # Adjust latent vector size if needed\n","\n","    with torch.no_grad():  # Disable gradients for generation\n","        generated_images = generator(noise).squeeze(1)  # Squeeze to remove channel dimension\n","\n","    # Create output directory with date and time\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    output_dir = f\"output/generated_images_{timestamp}\"\n","    os.makedirs(output_dir, exist_ok=True)  # Create directory if it doesn't exist\n","\n","    # Optionally, save generated images as .nii files\n","    if save_as_nii:\n","        for i in range(num_images):\n","            img_np = generated_images[i].cpu().numpy()\n","            nii_img = nib.Nifti1Image(img_np, affine=np.eye(4))  # Convert numpy array to NIfTI format\n","            nii_file_path = os.path.join(output_dir, f\"generated_image_{i+1}.nii\")\n","            nib.save(nii_img, nii_file_path)\n","            print(f\"Generated and saved: {nii_file_path}\")\n","\n","# Generate and save synthetic MRI images\n","generate_synthetic_images(generator, num_images=3)\n"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
